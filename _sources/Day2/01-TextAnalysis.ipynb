{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f42023e-9c42-4fab-9480-c06415ec3211",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "Part 1: Basic text analysis\n",
    "\n",
    "Part 2: Cleaning and normalization\n",
    "\n",
    "Ideas for complex/advanced applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450aca1-4ddc-4b71-bd15-9d9139d3709e",
   "metadata": {
    "raw_mimetype": "pdf",
    "tags": []
   },
   "source": [
    "### Part 1: Basic Text Analysis \n",
    "\n",
    "NLTK (Natural Language Toolkit): \n",
    "\n",
    "A python library with functions specifically designed to analyze natural (not-computer) language.\n",
    "\n",
    "NLTK needs to be imported in any python script that uses it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8d0961-d4b6-4e10-bfe7-2786eb4d5f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from urllib.request import urlopen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39457a47-ee99-4886-a9ee-654a79c4892b",
   "metadata": {},
   "source": [
    "NLTK comes with two built-in texts, *Moby Dick* and *Sense and Sensibility.* Note the assumptions about how NLTK will be used: novels, long, canonical..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c76f42-681b-4458-9f22-464e6d872a29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **NLTK functions: Concordance()**\n",
    "\n",
    "- Called on a Text object and takes a string (a sequence of characters) as an argument\n",
    "\n",
    "- text_variable.condordance(string_arg) \n",
    "\n",
    "- Calling condordance(\"word\") returns the words that surround “word” in different sentences, helping us to get a glimpse of the contexts in which the word shows up. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51a67e-d825-4383-95e0-e2c9616c70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the icon that looks like a folder with a plus sign in the left menu, create a new folder called textfiles\n",
    "# add one or more text files\n",
    "files_path = 'textfiles'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ae08a8-3ef3-40ba-90de-ca0ccd9dbbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: The Liberator Our martyred president , William McKinley...>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to bring in file from within JupyterHub\n",
    "my_file = open(\"Liberator91901.txt\", \"r\")\n",
    "file_txt = my_file.read()\n",
    "txt_tokens = nltk.word_tokenize(file_txt)\n",
    "txt_prepped = nltk.Text(txt_tokens)\n",
    "\n",
    "txt_prepped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32717810-57c2-4c25-96d8-20d1d3a39039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bring in file from URL\n",
    "#my_url = \"https://raw.githubusercontent.com/ucla/ca-dhri/main/Day2/Liberator91901.txt\"\n",
    "\n",
    "#file = urlopen(my_url)\n",
    "#liberator_raw = file.read()\n",
    "#liberator_txt = liberator_raw.decode()\n",
    "#txt_tokens = nltk.word_tokenize(liberator_txt)\n",
    "#liberator = nltk.Text(txt_tokens)\n",
    "\n",
    "#let's make sure we created a text object\n",
    "#liberator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173c4f08-6a74-4e17-94cb-71d7e503985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 26 matches:\n",
      "of white men changed their tune Lynch law appears to be on the increase in this\n",
      "ishment under the solemn forms of the law is an effective deterrent of crime . \n",
      "ther , with ever-lessening regard for law and justice . Negro crime can never b\n",
      "will be punished , if at all , by the law . It was not the uncertainty of the l\n",
      "w . It was not the uncertainty of the law that impelled the mob , but its certa\n",
      "led the mob , but its certainty . The law would have singled out the guilty wre\n",
      "le motive but contempt or defiance of law . If two white men had to be killed t\n",
      "dy forfeited , but the majesty of the law was worth saving at any cost . Fresno\n",
      "s one of the worst known to ethics or law . To what can be ascribed the cause o\n",
      "iased observer that the laxity of the law against lynchers in the South has had\n",
      "pon his head the violent hands of the law and the hatred of mankind . But the m\n",
      "re , become popular , and respect for law ceases to be a duty or a virtue . Thi\n",
      "ious . If the nation is to live , mob law must go . The president a victim of t\n",
      "s the assassin himself by setting the law at defiance and bringing our civiliza\n",
      "more strictly upon the enforcement of law and order . There has been altogether\n",
      ", something has been said . While the law sleeps , mob law increases . For ever\n",
      "een said . While the law sleeps , mob law increases . For every negro lynched a\n",
      "of Ben Tilman that he and his gang of law breakers have decided to set the cons\n",
      "hered by mobs , bent on violating the law is not worthy of the consideration of\n",
      "he city as the guest of his mother in law , Mrs. Thornton . The readers and fri\n",
      "ciety through the ferocities of lynch law . Every act of mob violence is a laps\n",
      "oration or institution , or overrides law , promotes anarchy . There must be a \n",
      "archy . There must be a high reign of law or a low reign of lawlessness . Law m\n",
      "f law or a low reign of lawlessness . Law must be made honorable by honorable a\n",
      "orable by honorable administration of law . Warren F. Day , D.D. , senior pasto\n"
     ]
    }
   ],
   "source": [
    "#call concordance on the word \"law\"\n",
    "txt_prepped.concordance(\"law\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2157c4-bca7-470f-af3c-3a9974685c52",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **NLTK functions: Similar()**\n",
    "\n",
    "-text.similar(string_arg)\n",
    "\n",
    "-Like concordance, similar will find the contexts of the string variable it is given, but it can also compare the content of these contexts to all other words, looking for words that are used in similar contexts to the given argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456020e1-7f2f-47e3-b48f-4e2a7d5ca237",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.similar(\"law\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3461ce7-fcc8-4ec2-95f7-5ceeb376002b",
   "metadata": {},
   "source": [
    "#### **NLTK functions: dispersion plot**\n",
    "\n",
    "-text.dispersion_plot(list_arg)\n",
    "\n",
    "-Takes a list of strings as input (not a single string!) and outputs a graph of the instances where each word appears. If you want to make a plot for one string, pass the function a one-object list [“example”]\n",
    "\n",
    "-Note: dispersion_plot() is helpful for seeing how language changes over time or over narrative arcs. It might be more useful on a large collection of newspapers over time than on a single newspaper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409785c-b4cd-4cf5-929d-1d7c6433e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.dispersion_plot([\"law\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b89493-ae7a-44a4-981e-5404fa28b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.dispersion_plot([\"law\",\"furniture\",\"Angeles\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98463815-a2f8-4533-9e13-7618098bf3b8",
   "metadata": {},
   "source": [
    "#### **NLTK functions: count()**\n",
    "\n",
    "-Takes a word as an argument and returns a count of each instance of that word in a text. \n",
    "\n",
    "-It is case sensitive (we will address cases in data cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4ec46-2c37-4b8e-a14c-8779b3966177",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.count(\"Angeles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3993e4-c61f-4aa9-ba42-df71bfafc2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.count(\"angeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b2bd0-c2f5-4c7a-bb3b-3b6e829c9f19",
   "metadata": {},
   "source": [
    "### Practice in Breakout Rooms\n",
    "\n",
    "Can you think of how we could generate a concordance that would allow us to extract addresses from the text? What might we do with that information?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebacef38-7fa7-4ab9-b0ac-f17675fb17ab",
   "metadata": {},
   "source": [
    "#### **Python operations on NLTK objects: len(), set()**\n",
    "\n",
    "So far, we have been using the built-in NLTK corpus to analyze our text object. We can also use regular python expressions on it:\n",
    "\n",
    "**len(text_object)** returns the length of the nltk object, that is, the number of words in the text. In a pre-cleaning text, this will include punctuation and metadata. \n",
    "\n",
    "**set(text_object)** creates a set (a list without duplicates) of all the unique words \n",
    "\n",
    "**len(set(text_object)** returns — you guessed it — the length of the set of unique words, ie, the number of unique words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825651c-82a8-48b1-8b72-40bea27c1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(liberator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d9d04-260f-497f-911b-a547af9b6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(liberator)\n",
    "sorted(set(liberator))[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f4e89-e499-4308-bf1b-7972582f725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(liberator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efc3c7-2b8b-43a7-98a5-38c6e5ee525e",
   "metadata": {},
   "source": [
    "### Part 2: Cleaning and Normalizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb4c67-20e1-4fa2-83df-a67d506a5b82",
   "metadata": {},
   "source": [
    "#### **Removing capitalization and punctuation**\n",
    "\n",
    "Type vs. token: \n",
    "- angeles vs. Angeles vs. ANGELES are distinct types\n",
    "    \n",
    "- A token is an instance of a type\n",
    "\n",
    "- nltk.count(“angeles”) counts the number of tokens of that type\n",
    "\n",
    "If the distinction between cases isn't important in your analysis, making all values of a text lowercase can be useful.\n",
    "\n",
    "So we'll start normalizing the text by making all words lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202a85f-6829-43d7-a4a6-c8cb49dbc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_lowercase = [word.lower() for word in liberator] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303606b-852c-484e-9bf4-c6c48377b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_lowercase.count(\"angeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752ba7f-db75-487e-8c4c-dd9997ce45eb",
   "metadata": {},
   "source": [
    "#### **Remove all punctuation**\n",
    "\n",
    "Lets run this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152f270-eb4c-4a0c-b654-bf52c9436d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_lowercase_textonly = [word.lower() for word in liberator if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c91ca-8ae0-4792-b4cd-b7ed9ae5977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What did we just do, though?\n",
    "#liberator_lowercase_textonly = [word.lower() for word in liberator if word.isalpha()] is shorthand for this function\n",
    "\n",
    "liberator_lowercase_textonly = []\t\t\t\t#define an empty list called liberator_lowercase_only\n",
    "\n",
    "for w in liberator:\t\t\t\t\t        #For each word (\"w\") in our existing text object \n",
    "\n",
    "\tif w.isalpha():\t\t\t\t        #if the word (“w”) is letters (not punctuation)\n",
    "        \n",
    "\t\tliberator_lowercase_textonly.append(w.lower())  \t#make it lowercase and add to our new list\n",
    "\n",
    "        #if the word is not alpha, the for loop will move on to the next word \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42a159-0b2f-49bf-9c08-22f56073bcea",
   "metadata": {},
   "source": [
    "TIP: be smart about your variable names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6b1d7-2222-4cd8-8e7b-f27d1aef27f8",
   "metadata": {},
   "source": [
    "#### **Removing stop words**\n",
    "\n",
    "- (\"the,\" \"an,\" \"a,\" etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc710393-fc20-4b0a-ae46-fa36845136c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a predefined list of stopwords, how nice!\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#note, stopwords' type isn't a List, it's a WordListCorpusReader\n",
    "print(type(stopwords))\n",
    "\n",
    "#if we want a \"real\" list, we need to call the words attribute\n",
    "print(type(stopwords.words()))\n",
    "      \n",
    "#here's what we have:\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690cb1fd-3870-45c5-ab73-596227d8ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of stopwords in our text\n",
    "\n",
    "#make sure you import stopwords somewhere in the script before you call it\n",
    "liberator_sans_stops = []\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "#define a new list\n",
    "for word in liberator_lowercase_textonly:\t\t\t\t#for each word in our cleaner list,\n",
    "    if word not in stops:\t                        #if that word isn’t in the list of stopwords,\n",
    "        liberator_sans_stops.append(word)\t\t        #add it to our new list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901649d8-4b60-4a82-94b2-258902fbcc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#did it work?\n",
    "liberator_sans_stops.count(\"angeles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31f0db-c436-4c0e-b20f-9d37c0702025",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_sans_stops.count(\"of\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76395b3-5e02-4326-8f5d-29b52dbf01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_sans_stops.count(\"after\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c43b5-c978-410d-8b95-601bf8b17be9",
   "metadata": {},
   "source": [
    "#### **Lemmatizing words**\n",
    "\n",
    "- Lemmatization shrinks words to their grammatical root\n",
    "    - example, cats ⭢ cat and walked ⭢ walk\n",
    "  \n",
    "- This gets complicated in the case of men ⭢ man and sang ⭢ sing \n",
    "\n",
    "- Lemmatization looks up a word in a reference dictionary and finds the appropriate root (though this still is not entirely accurate and takes a long time, since each word must be looked up in a reference)\n",
    "\n",
    "- NLTK comes with pre-built stemmers and lemmatizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a1a66-3eab-42c8-b329-ffb73f1a9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\t\n",
    "\n",
    "#create an instance of it for our function\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\t\n",
    "\n",
    "print(wordnet_lemmatizer.lemmatize(\"children\"))\n",
    "\n",
    "print(wordnet_lemmatizer.lemmatize(\"better\"))\n",
    "\n",
    "#for a word like “better,” need to specify grammatical function\n",
    "print(wordnet_lemmatizer.lemmatize(\"better\", pos='a'))\n",
    "print(wordnet_lemmatizer.lemmatize(\"better\", pos='n'))\n",
    "\n",
    "#Parts of Speech\n",
    "#ADJ, ADJ_SAT, ADV, NOUN, VERB = \"a\", \"s\", \"r\", \"n\", \"v\"\n",
    "\n",
    "liberator_lemma = []\n",
    "for word in liberator_sans_stops:\n",
    "    word_lem = wordnet_lemmatizer.lemmatize(word)\n",
    "    liberator_lemma.append(word_lem)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bdc5fd-7a63-4179-ba85-7da45dec7d2d",
   "metadata": {},
   "source": [
    "### Part 3: Basic text analysis with our clean text\n",
    "\n",
    "Because we've lemmatized our text, the results of functions like concordance, similar, and count will change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca615c-797d-424a-a37c-9ec628fcc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to make our clean text an NLTK object to use the functions\n",
    "liberator_clean = nltk.Text(liberator_lemma)\n",
    "\n",
    "liberator_clean.concordance('law')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be138a-b5c7-4c60-9376-196ecf4a05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.concordance(\"children\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf20d05-0a50-4e66-9171-c65fc614e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.concordance(\"child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca651f-ad38-4b2b-ab51-bbf82c4524a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.concordance(\"anarchist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feab4c3-5a4a-4c90-bdce-4660c881c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.concordance(\"lawless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ad90d-d5ef-44aa-a1cc-201c3fb064ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de2aec-771d-4f82-ae40-b58dec2d367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.similar(\"child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617aa5a-4e9d-48ef-9143-cb6dd35a7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.dispersion_plot([\"law\",\"america\",\"anarchist\",\"assassin\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ba6cfb-4ac9-4882-9bea-3dc3f941bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.dispersion_plot([\"law\",\"America\",\"anarchist\",\"assassin\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f06dc-e03b-4f47-8008-b823516b736d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
